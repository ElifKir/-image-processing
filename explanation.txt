ENGLISH DESCRIPTION
	
import cv2    #OpenCV library.
import time   #Required to do time-related operations.
#Contributes OpenCV and time libraries to the project.

#I saved the video with the name "MOT17-09-DPM-raw.webm".
#I uploaded the Python script file I created with the ".py" extension with a view name and script information.

cap = cv2.VideoCapture("MOT17-09-DPM-raw.mp4")

#The "cv.VideoCapture(*args)" class is used for image capture and video capture from the camera or for operations with video files.
#I used cv.VideoCapture(*args) command here to read video from file.
#I created a variable called "cap" and used the VideoCapture command to do the video capture.
#Then I added the video name to include the video.

object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)

#Background subtraction is a method often used in image processing applications.
#It is generally used to catch and follow moving objects (people, vehicles, products, etc.) on a stable ground.
#"BackgroundSubtractorMOG, BackgroundSubtractorMOG 2 and BackgroundSubtractorGMG" method has been developed for background subtraction in #OpenCV library.
#Therefore, I did background removal by saying cv2.createBackgroundSubtractorMOG2 here.

#Threshold is the threshold value. It is a method used to convert the input image to binary image.
#Binary image is the definition of the image as black and white.
#Threshold is used for different purposes such as reducing noise on the image or identifying objects.
#That's why we assigned the value Threshold'40. Thus, we convert our input to binary image. We also get rid of unwanted noise.

while True:
    ret, frame = cap.read()
    height, width, _ = frame.shape

#This operation is used to get images from the video.
#The "ret parameter" returns true false whether the camera is working or not.
#The "ret parameter" obtains a return value based on the wrong getting the camera frame.
#"Frame" acquires the next frame in the camera (with "cap").

#cap.read() returns a boolean(True/False) logic operation.
#If the frame was read correctly, it will output True. This will allow us to check the video.
#So I can check the end of the video by checking this return value.

#I set the height and width according to the size of the frames.

roi = frame[0: 720,0:1600]  

#I created a variable named roi. I added where to get it. I wrote a frame to get it from the frame.
#I set the x and y coordinates.
#I set it to take the range from 0 to 720. This is the y coordinate.
#The range from 0 to 1600 is the x coordinate.

 mask = object_detector.apply(roi)   
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)


#The mask operation is used to detect pixels corresponding to the entered values ​​in the color space and returns an image in binary format, that is, consisting of 1s and 0s.
#The white places in the image are the areas where our object is located, and the black places are the values ​​that do not match the entered color code.
#I created a variable named mask and applied the coordinates I made in the roi variable to the object_detector variable I had created before, with apply.


#Contours is a curve that connects all continuous points of the same color and intensity along the border.
#Contours are a very useful tool for shape analysis, object detection and recognition.
#For a more accurate result, a binary (black and white) image should be used when seeking contours.
#With the "FindContours" method, the picture with its contours completely changes and becomes unusable in its original form.
#Here, first the original image is read, first converted to gray scale, and the converted gray scale image is converted to binary format.
#Contours were found in the cv2.findContours() operation.
#cv.RETR_TREE takes all contours and reconstructs a complete hierarchy of nested contours.
#If it is desired to draw a contour consisting of a straight line, all contour information is not needed, it is sufficient to know the coordinates of the start and end points.
#In this case, it is sufficient to use the "cv2.CHAIN_APPROX_SIMPLE" command.


for cnt in contours:
        
        area = cv2.contourArea(cnt)     
        if area > 2000:  

#I created a variable called cnt.
#The cv.contourArea() method is used to determine the area of ​​the contour.
#The contours list contains all the contours in our frame. If the contour list is not empty, we process them one by one.
#area > 2000 is to ensure that contours smaller than a 2000px area do not draw rectangles around them.

  x, y, w, h = cv2.boundingRect(cnt)     
            cv2.rectangle(roi, (x, y), (x + w, y + h), (10, 250, 0), 3) 


#The cv2.boundingRect() OpenCV function is used to draw an approximate rectangle around the binary image.
#This function is mainly used to highlight the region of interest after acquiring contours from an image.
     time.sleep(0.100)

#The sleep() function is one of the most frequently used tools of the time module.
#By using this function, we can interrupt the operation of our codes for certain periods.
#For example, if we give the sleep() function the parameter 0.5, we get the pause time to be 500 milliseconds.
#Here, we have given 0.001 to the sleep function. So I got suspended at one thousandth of a second.


    cv2.imshow("Frame", frame)
    cv2.imshow("Mask", mask)


#I had a "frame" and a "mask" variable that I had created before.
#I wrote it inside the cv2.imshow method.
#In this way, the name of my video that has a frame on the screen is "frame" mask, that is, the name of my video that is black and white becomes "mask".


key = cv2.waitKey(10)
    if key == 27:
        break
    if cv2.waitKey(1) & 0xff == ord("q"):
#The program closes when the "q" key is pressed.  
        break

#"cv2.waitKey" is used for keyboard method. The parameters it will take are time in milliseconds. This function waits the specified time for any keyboard event.
#The program continues when nothing is pressed.
#The cv2.waitKey(n) function I wrote last is the keyboard binding function used in OpenCV.
#It takes an argument as a parameter, which represents the time in milliseconds.
#During this time, the program pauses, waiting for the time to run out or encountering any keyboard events to continue.
#If no parameter is passed, a value of 0 (meaning forever) is given as default, which is used to listen to the keyboard event without a time limit.


cap.release()
cv2.destroyAllWindows()


#We use "cv2.destroyAllWindows()" to close the windows we created.
#When the loop is broken we release the camera object and clear the memory by closing all opened windows.



TURKISH DESCRIPTION
(TÜRKÇE AÇIKLAMA)

import cv2      #OpenCV kütüphanesi.
import time     #Zamanla ilgili işlemleri yapmak için gereklidir.
#OpeCV ve time kütüphanelerini projeye dahil ettik.

#Videoyu "MOT17-09-DPM-raw.webm" adıyla kaydettim.
#Oluşturduğum ".py" uzantılı Python script dosyama videoyu bir değişken adı ile aşağıdaki komut satırı ile yükledim.

cap = cv2.VideoCapture("MOT17-09-DPM-raw.mp4")

#Kameradan görüntü alma ve video çekme işlemlerinde veya video dosyaları ile yapılacak işlemler için "cv.VideoCapture(*args)" sınıfı kullanılmaktadır.
#Dosyadan video okumak için cv.VideoCapture(*args) komutunu burada kullandım.
#"cap" adında bir değişken oluşturdum ve video çekme işlemini yapmak için VideoCapture komutunu kullandım. 
#Ardından videoyu dahil etmek için video adını ekledim.

object_detector = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=40)   

#Arka plan çıkarma işlemi görüntü işleme uygulamalarında sıklıkla kullanılan bir yöntemdir.
#Genellikle sabit bir zemin üzerindeki hareketli nesneleri (insan, araç, ürün vb.) yakalamak ve takip etmek için kullanılır.  
#OpenCV kütüphanesinde arka plan çıkarma işlemi için "BackgroundSubtractorMOG, BackgroundSubtractorMOG 2 ve BackgroundSubtractorGMG" yöntemi geliştirilmiştir.
#Bu nedenle burada cv2.createBackgroundSubtractorMOG2 diyerek arka plan çıkarma işlemi yaptım.

#Threshold eşik değeridir. Giriş olarak verilen görüntüyü ikili görüntüye çevirmek için kullanılan bir yöntemdir.
#İkili görüntü (binary), görüntünün siyah ve beyaz olarak tanımlanmasıdır.
#Threshold, görüntü üzerindeki gürültüleri azaltmak veya nesne belirlemek gibi farklı amaçlar için kullanılır.
#Bu yüzden Threshold'40 değerini verdik. Böylece girdimizi ikili görüntüye çevirmiş oluruz. Ayrıca istenmeyen gürültülerden de kurtulmuş oluruz. 

while True:
    ret, frame = cap.read()
    height, width, _ = frame.shape    

#Bu işlem videodan görüntü almak için kullanılır.
#Ret parametresi kameranın çalışıp çalışmadığı ile ilgili true false değeri döndürüyor.
#"Ret", kamera çerçevesini almanın yanlış olduğuna göre geri dönüş değeri elde eder.
#"Frame", kameradaki bir sonraki kareyi elde eder ("cap" ile). 

#cap.read() , bir boolen(True/False) mantık işlemi döndürür. 
#Eğer çerçeve(frame) doğru bir şekilde okunduysa, doğru(True) çıkışını verecektir. Bu bize videonun kontrol edilmesi olanağını verecektir.
#Böylece bu dönüş değerini kontrol ederek videonun sonunu kontrol edebilirim.

#height (yükseklik) ve width(genişliğini) framelerin boyutuna göre ayarladım.


    roi = frame[0: 720,0:1600]     
    
#roi adında bir değişken oluşturdum. Nereden alacağımı yanına ekledim. Frameden alacağım için frame yazdım. 
#x ve y koordinatlarını belirledim. 
#0'dan 720'ye kadar olan aralığı alsın olarak belirledim. Burası y koordinatıdır. 
#0'dan 1600'e kadar olan aralık ise x koordinatıdır. 


    mask = object_detector.apply(roi)   
    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)   
    
#Mask işlemi renk uzayındaki girilen değerlere denk gelen pikselleri tespit etmede kullanılır ve binary formatta yani 1 ve 0 'lardan oluşan bir görüntü döndürür. 
#Görüntüde ki beyaz yerler nesnemizin bulunduğu alanlar, siyah yerlerse girilen renk koduna uyuşmayan değerlerdir.
#mask adında bir değişken oluşturdum ve daha önceden oluşturmuş olduğum object_detector değişkenine roi değişkeninde yapmış olduğum koordinatları apply ile uygulamış oldum. 

#Konturlar aynı renk ve yoğunluğa sahip olan tüm kesintisiz noktaları sınır boyunca birleştiren bir eğridir. 
#Konturlar şekil analizi,nesne algılama ve tanıma için çok yararlı bir araçtır.
#Kontur bulunması istenirken daha doğru sonuç için binary(siyah-beyaz) formunda resim kullanılmalıdır.
#"FindContours" yöntemiyle konturleri bulunan resim komple değişir orjinal halini bir daha kullanılamaz hale gelir. 
#Burada ilk olarak orjinal resim okunup önce gri skalaya çevirilmiş ve gri skalaya çevrilen resim binary formata getirilmiştir.
#cv2.findContours() işleminde konturlar bulunmuştur.
#cv.RETR_TREE ,tüm konturları alır ve iç içe konturların tam bir hiyerarşisini yeniden oluşturur. 
#Düz bir çizgiden oluşan bir konturu çizdirmek istenirse bütün kontur bilgilerine ihtiyaç yoktur başlangıç ve bitiş noktalarının koordinatlarını bilmek çizdirmek için yeterlidir. 
#Bu durumda ise "cv2.CHAIN_APPROX_SIMPLE" komutunu kullanmak yeterlidir. 

    
    for cnt in contours:
        
        area = cv2.contourArea(cnt)     
        if area > 2000:  
                
#cnt adında bir değişken oluşturdum.
#cv.contourArea() metotu konturun alanını belirlemek için kullanılır. 
#contours listesi çerçevemizde yer alan tüm konturları içerir. Eğer kontur listesi boş değilse, hepsini tek tek işleme sokarız.
#area > 2000 , 2000 piksellik bir alandan küçük konturların etrafına dikdörtgen çizilmemesini sağlamaktır. 
            

            x, y, w, h = cv2.boundingRect(cnt)     
            cv2.rectangle(roi, (x, y), (x + w, y + h), (10, 250, 0), 3)    
#cv2.boundingRect() OpenCV işlevi, ikili görüntünün etrafına yaklaşık bir dikdörtgen çizmek için kullanılır. 
#Bu işlev, esas olarak bir görüntüden konturlar elde ettikten sonra ilgilenilen bölgeyi vurgulamak için kullanılır.
    time.sleep(0.100)
    
#sleep() fonksiyonu, time modülünün en sık kullanılan araçlarından bir tanesidir.
#Bu fonksiyonu kullanarak kodlarımızın işleyişini belli sürelerle kesintiye uğratabiliriz.
#Örnek olarak eğer sleep() fonksiyonuna 0.5 parametresini verirsek, duraklama süresinin 500 milisaniye olmasını sağlarız.
#Burada ise sleep fonksiyonuna 0.001 verdik. Yani saniyede binde bir askıya aldım. 
    
    cv2.imshow("Frame", frame)
    cv2.imshow("Mask", mask)     

#Daha önceden oluşturmuş olduğum “frame” ve “mask” değişkenim vardı.
#cv2.imshow metodunun içerisine yazdım. 
#Bu sayede ekranda frame olan videomun adı “frame” mask yani siya beyaz olan videomun adı ise “mask” olmuş olur.


    key = cv2.waitKey(10)
    if key == 27:
        break
    if cv2.waitKey(1) & 0xff == ord("q"):
# "q" tuşuna basıldığında program kapanır.   
        break
    
#Klavye metodu için "cv2.waitKey" kullanılır. Alacağı parametreler milisaniye cinsinden zamandır. Bu fonksiyon herhangi bir klavye olayı için belirtilen süre kadar bekler.
#Herhangi bir şeye basılmadığında program devam eder.
#Son olarak yazdığım cv2.waitKey(n) fonksiyonu, OpenCV de kulanılan keyboard binding fonksiyonudur. 
#Parametre olarak içine bir argüman alır ve bu argüman milisaniye cinsinden süreyi ifade eder. 
#Bu süre boyunca program durur, devam etmek için sürenin bitmesini veya herhangi bir keyboard event’i ile karşılaşmayı bekler.
#Eğer parametre geçirilmezse, 0 değeri (forever demek) default olarak verilir ki bu süre kısıtı olmadan keyboard event dinlemeye yarar.
cap.release()
cv2.destroyAllWindows()

#Yarattığımız pencereler kapatmak için "cv2.destroyAllWindows()" kulllanırız. 
#Döngü kırıldığında kamera nesnesini serbest bırakır ve açılmış tüm pencereleri kapatarak belleği temizleriz.